{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and storing data utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = 'top_CS_researcher_by_h_index.json'\n",
    "\n",
    "def read_data(filepath=filename):\n",
    "    try:\n",
    "        with open(filepath, 'r') as fp:\n",
    "            return json.load(fp)\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "def store_data(data, filepath=filename):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        return json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Publications for an author\n",
    "\n",
    "* We find the top authors in Computer Science - based on `h-index`\n",
    "* We find the `top 100 pubs` for every author and then\n",
    "* We calculate\n",
    "    - h-index\n",
    "    - c-score (log(total_citations) + log(h) + log(hm) + log(%first_author) + log(%first_last) + log(%first_last_single)\n",
    "    - h-leadership-index (inverted bell curve)\n",
    "\n",
    "* Things to remember:\n",
    "    - we are not ranking individuals but creating an index\n",
    "* Other notes\n",
    "    - cscore does not include Field-wise citation index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import pandas as pd\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "# Read the Stanford 2% ranking excel file\n",
    "df = pd.read_excel('Table_1_Authors_career_2022_pubs_since_1788_wopp_extracted_202310.xlsx', sheet_name='Data', engine='openpyxl')\n",
    "# We are only considering the Computer Science subject for this study\n",
    "df = df.loc[df['sm-field'] == 'Information & Communication Technologies']\n",
    "# NOTE: The cutoff year is 2022,and h column name changes based on cutoff year\n",
    "df = df.sort_values(by='h22', ascending=False)\n",
    "\n",
    "# A mapping between Stanford's top 2% ranking `sm-field` and Scopus API `SUBJECTAREA`\n",
    "subject_areas_mapping = {\n",
    "    'Information & Communication Technologies': ['COMP', 'MULT']\n",
    "}\n",
    "\n",
    "# Set up your Scopus API key\n",
    "api_key = '5aa908d24ec7e71ef0cf68cb3bff134d'\n",
    "\n",
    "# Define the Scopus API endpoint for author search\n",
    "scopus_search_url = 'https://api.elsevier.com/content/search/author'\n",
    "\n",
    "# Define the Scopus API endpoint for retrieving author's publications\n",
    "scopus_search_publications_url = 'https://api.elsevier.com/content/search/scopus'\n",
    "\n",
    "# Define the Scopus Abstract Retrieval API to get detailed information about the publication\n",
    "scopus_abstract_url = f'https://api.elsevier.com/content/abstract/eid'\n",
    "\n",
    "# Set up headers with your API key\n",
    "headers = {\n",
    "    'X-ELS-APIKey': api_key,\n",
    "}\n",
    "\n",
    "\n",
    "# Utility methods\n",
    "def get_author_names(author_full_name):\n",
    "    # Split the full name into first and last names\n",
    "    names = author_full_name.split(', ', 1)\n",
    "    first_name = names[-1]\n",
    "    last_name = names[0] if len(names)==2 else ''\n",
    "    return first_name, last_name\n",
    "\n",
    "def get_country_name(country_code):\n",
    "    try:\n",
    "        country_name = pycountry.countries.get(alpha_3=country_code).name\n",
    "        return country_name\n",
    "    except AttributeError:\n",
    "        # Handle cases where the country code is not found\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def sort_author(author, country, affiliation):\n",
    "    cites = author.get('document-count', 0)\n",
    "    country_name = author.get('affiliation-current', {}).get('affiliation-country', '')\n",
    "    affiliation_name = author.get('affiliation-current', {}).get('affiliation-name', '')\n",
    "    return cites, country_name == country, affiliation_name == affiliation\n",
    "\n",
    "\n",
    "# Function to search for an author in Scopus using name, affiliation, country, and field\n",
    "def search_author(author_name, affiliation, country_code, field, exclude=list()):\n",
    "    first_name, last_name = get_author_names(author_name)\n",
    "    subject_areas = subject_areas_mapping.get(field, [])\n",
    "    country_name = get_country_name(country_code)\n",
    "\n",
    "    query = f'AUTHLASTNAME({last_name}) AND AUTHFIRST({first_name}) AND {\" OR \".join(map(lambda s: f\"SUBJAREA({s})\", subject_areas))}'\n",
    "    response = requests.get(scopus_search_url, params={'query': query, 'count': 200}, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get('search-results', {}).get('entry', [])\n",
    "        # exclude authors already in the list\n",
    "        results = [r for r in results if r.get('dc:identifier') not in exclude]\n",
    "        # sort the authors based on the number of documents, affiliation country, and affiliation name\n",
    "        sort_key = partial(sort_author, country=country_name, affiliation=affiliation)\n",
    "        results.sort(key=sort_key, reverse=True)\n",
    "        results.sort(key=lambda x: x.get('document-count', 0), reverse=True)\n",
    "        results.sort(key=lambda x: x.get('affiliation-current', {}).get('affiliation-country', '') == country_name, reverse=True)\n",
    "\n",
    "        return results[0] if results else None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch all publications for an author using Scopus Author ID\n",
    "def fetch_author_publications(author_id, publications=None, start_index=0, limit=100):\n",
    "    if not publications:\n",
    "        publications = []\n",
    "\n",
    "    query = f'AU-ID({author_id})'\n",
    "    response = requests.get(scopus_search_publications_url, params={\n",
    "        'query': query,\n",
    "        'start': start_index,\n",
    "        'count': min(limit, 200), # Maximum can be 200\n",
    "        'sort': 'citedby-count'\n",
    "    }, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        search_results = response.json().get('search-results', {}).get('entry', [])\n",
    "\n",
    "        for entry in search_results:\n",
    "            authors = []\n",
    "            abstract_url = f'{scopus_abstract_url}/{entry.get(\"eid\", \"\")}'\n",
    "            response_abstract = requests.get(abstract_url, headers=headers)\n",
    "            if response_abstract.status_code == 200:\n",
    "                author_data = xmltodict.parse(response_abstract.text).get('abstracts-retrieval-response', {}).get('authors', []).get('author', [])\n",
    "                if not isinstance(author_data, list): # If only one author\n",
    "                    author_data = [author_data]\n",
    "                authors = map(lambda a: {\n",
    "                        'scopus_id': a['@auid'],\n",
    "                        'name': a.get('ce:indexed-name', ''),\n",
    "                    }, author_data)\n",
    "\n",
    "            publication_data = {\n",
    "                'title': entry.get('dc:title', ''),\n",
    "                'eid': entry.get('eid', ''),\n",
    "                'citations': entry.get('citedby-count', 0),\n",
    "                'authors': list(authors),\n",
    "                'publication_name': entry.get('prism:publicationName', ''),\n",
    "                'issn': entry.get('prism:issn', ''),\n",
    "                'cover_date': entry.get('prism:coverDate', ''),\n",
    "                'venue': entry.get('prism:aggregationType', ''),\n",
    "                'volume': entry.get('prism:volume', ''),\n",
    "                'issue': entry.get('prism:issueIdentifier', ''),\n",
    "                'page_range': entry.get('prism:pageRange', ''),\n",
    "                'doi': entry.get('prism:doi', ''),\n",
    "            }\n",
    "            publications.append(publication_data)\n",
    "\n",
    "        # Fetch the next set of publications if available and limit is not reached\n",
    "        start_index += len(search_results)\n",
    "        if limit > start_index and start_index < int(response.json().get('search-results', {}).get('opensearch:totalResults', 0)):\n",
    "            return fetch_author_publications(author_id, publications, start_index)\n",
    "\n",
    "    return publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code\n",
    "scopus_results=read_data()\n",
    "def fetch_authors(stop_at=300):\n",
    "    # Iterate through the rows of the DataFrame\n",
    "    for index, (row_index, row) in enumerate(df.iterrows()):\n",
    "        if index < len(scopus_results):\n",
    "            # Since data was previously obtained for these authors, we can skip them\n",
    "            print(f'{row[\"authfull\"]}: Skipped')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            author_name = row['authfull']\n",
    "            author_cscore = row['c']\n",
    "            affiliation = row['inst_name']\n",
    "            country_code = row['cntry']\n",
    "            field = row['sm-field']\n",
    "            print(author_name)\n",
    "\n",
    "            # Search for the author in Scopus\n",
    "            author_search_result = search_author(\n",
    "                author_name,\n",
    "                affiliation,\n",
    "                country_code,\n",
    "                field,\n",
    "                map(lambda x: x['scopus_id'], scopus_results)\n",
    "            )\n",
    "\n",
    "            # Process the search result as needed\n",
    "            if author_search_result is not None:\n",
    "                author_id = author_search_result.get('dc:identifier', '').split(':')[-1]\n",
    "                author_publications = fetch_author_publications(author_id)\n",
    "                scopus_results.append({\n",
    "                    'scopus_id': author_id,\n",
    "                    'name': author_name,\n",
    "                    'cscore': author_cscore,\n",
    "                    'publications': author_publications\n",
    "                })\n",
    "                if index == stop_at:\n",
    "                    break\n",
    "            else:\n",
    "                raise Exception(f\"Author not found for: {author_name}, Affiliation: {affiliation}, Country: {country_code}, Field: {field}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    store_data(scopus_results)\n",
    "    # return scopus_results\n",
    "\n",
    "fetch_authors()\n",
    "# TODO: Find correlation between hl-index, h-index and c-score\n",
    "# Find the remaining usage-limit for Scopus API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scopus_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics for the Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average leadership weight: 0.6065245990857342\n",
      "Average leadership weight: 0.4604898130691024\n",
      "Average leadership weight: 0.6287199584598006\n",
      "Average leadership weight: 0.7603912622422612\n",
      "Average leadership weight: 0.8205374736592219\n",
      "Average leadership weight: 0.92560003351789\n",
      "Average leadership weight: 0.628993555857536\n",
      "Average leadership weight: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hardik/Desktop/research/metrics/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/hardik/Desktop/research/metrics/venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing author: Shen, Xuemin\n",
      "Average leadership weight: 0.8194952504882366\n",
      "Average leadership weight: 0.7359035051635059\n",
      "Average leadership weight: 0.9237729894257174\n",
      "Average leadership weight: 0.9485460074163139\n",
      "Average leadership weight: 0.0\n",
      "Error processing author: Akyildiz, Ian F.\n",
      "Error processing author: Tang, Xiaoou\n",
      "Error processing author: Schmid, Cordelia\n",
      "Error processing author: Vaidyanathan, Sundarapandian\n",
      "Error processing author: Shenker, Scott\n",
      "Error processing author: Cui, Tie Jun\n",
      "Error processing author: Shen, Dinggang\n",
      "Error processing author: Kanade, T.\n",
      "Error processing author: Hinton, Geoffrey\n",
      "Error processing author: Tong, Shaocheng\n",
      "Error processing author: Koller, Daphne\n",
      "Error processing author: Han, Zhu\n",
      "Error processing author: Stoica, Ion\n",
      "Error processing author: Darrell, Trevor\n",
      "Error processing author: Manning, Christopher D.\n",
      "Error processing author: Zhou, Mengchu\n",
      "Error processing author: Leskovec, Jure\n",
      "Error processing author: Faloutsos, Christos\n",
      "Error processing author: Ng, Andrew Y.\n",
      "Average leadership weight: 0.8687411347837204\n",
      "Average leadership weight: 0.6045103640854196\n",
      "Average leadership weight: 0.8150272759672434\n",
      "Average leadership weight: 0.8138216460882531\n",
      "Average leadership weight: 0.3333333333333333\n",
      "Average leadership weight: 0.0\n",
      "Error processing author: Leung, Victor C.M.\n",
      "Average leadership weight: 0.7795824905401917\n",
      "Average leadership weight: 0.9187364173989245\n",
      "Average leadership weight: 0.21584408869578373\n",
      "Average leadership weight: 0.7060820296445189\n",
      "Average leadership weight: 0.0\n",
      "Error processing author: Ding, Zhiguo\n",
      "Average leadership weight: 0.7694814888887639\n",
      "Average leadership weight: 0.914984190938388\n",
      "Average leadership weight: 0.7715422177270818\n",
      "Average leadership weight: 0.6966152601146711\n",
      "Average leadership weight: 0.8105870972964105\n",
      "Average leadership weight: 0.6233207933370873\n",
      "Average leadership weight: 0.9663670174801184\n",
      "Average leadership weight: 0.0\n",
      "Error processing author: Choo, Kim Kwang Raymond\n",
      "Average leadership weight: 0.24341496884485042\n",
      "Average leadership weight: 0.8749255770161514\n",
      "Average leadership weight: 0.3353811092094114\n",
      "Average leadership weight: 0.8174531205020709\n",
      "Error processing author: Li, Jian\n",
      "Average leadership weight: 0.7590569310698186\n",
      "Error processing author: Wu, Jie\n",
      "Error processing author: Chen, Xiaohong\n",
      "Error processing author: Vetterli, Martin\n",
      "Error processing author: Jia, Jiaya\n",
      "Error processing author: Li, Hongyi\n",
      "Average leadership weight: 0.0\n",
      "Error processing author: Jiao, Licheng\n",
      "Error processing author: Le, Quoc V.\n",
      "Error processing author: Chen, Min\n",
      "Average leadership weight: 0.0\n",
      "Error processing author: Mukherjee, Biswanath\n",
      "Error processing author: Picard, Rosalind W.\n",
      "Error processing author: Wang, Fei Yue\n",
      "Error processing author: Ney, Hermann\n",
      "Error processing author: Castillo, Oscar\n",
      "Error processing author: Durand, Fredo\n",
      "Error processing author: Efros, Alexei A.\n",
      "Error processing author: Itoh, Tatsuo\n",
      "Error processing author: Zuo, Wangmeng\n",
      "Error processing author: Liao, Xiao Feng\n",
      "Error processing author: McCallum, Andrew\n",
      "Error processing author: Chen, Bin\n",
      "Error processing author: Gong, Shaogang\n",
      "Error processing author: Pietikäinen, Matti\n",
      "Error processing author: Xu, Lida\n",
      "Average leadership weight: 0.0\n",
      "Error processing author: Lu, Huchuan\n",
      "Error processing author: Harman, Mark\n",
      "Error processing author: Liu, Yunhao\n",
      "Error processing author: Hong, Wei\n",
      "Error processing author: Wang, Meng\n",
      "Error processing author: Deng, Yong\n",
      "Error processing author: Zheng, Yu\n",
      "Error processing author: Ren, Kui\n",
      "Error processing author: Luo, Jiebo\n",
      "Error processing author: Yang, Laurence T.\n",
      "Error processing author: Zhao, Lili\n",
      "Error processing author: Li, Shutao\n",
      "Error processing author: Wang, Ling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Publications</th>\n",
       "      <th>Total citations</th>\n",
       "      <th>Median citations</th>\n",
       "      <th>h-index</th>\n",
       "      <th>h-frac-index</th>\n",
       "      <th>hm-index</th>\n",
       "      <th>h-leadership-index</th>\n",
       "      <th>% first author</th>\n",
       "      <th>% last author</th>\n",
       "      <th>% single author</th>\n",
       "      <th>Median author position</th>\n",
       "      <th>i10-index</th>\n",
       "      <th>Average number of Authors</th>\n",
       "      <th>Median number of Authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Herrera, Francisco</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tao, Dacheng</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yu, Philip S.</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jordan, Michael I.</td>\n",
       "      <td>95</td>\n",
       "      <td>3531</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>6.578947</td>\n",
       "      <td>65.789474</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huang, Thomas S.</td>\n",
       "      <td>21</td>\n",
       "      <td>347</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.277778</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wang, Xiaogang</td>\n",
       "      <td>97</td>\n",
       "      <td>2985</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>52.127660</td>\n",
       "      <td>5.319149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68</td>\n",
       "      <td>3.787234</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zhang, Rui</td>\n",
       "      <td>99</td>\n",
       "      <td>5733</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.708861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46</td>\n",
       "      <td>544.164557</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zhang, Lei</td>\n",
       "      <td>87</td>\n",
       "      <td>2562</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>15.789474</td>\n",
       "      <td>17.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5.184211</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Li, Xuelong</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zhang, David</td>\n",
       "      <td>79</td>\n",
       "      <td>3279</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Schölkopf, Bernhard</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zhou, Zhi Hua</td>\n",
       "      <td>91</td>\n",
       "      <td>2685</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>24.705882</td>\n",
       "      <td>16.470588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56</td>\n",
       "      <td>6.647059</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Davis, Larry S.</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pedrycz, Witold</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sun, Jian</td>\n",
       "      <td>99</td>\n",
       "      <td>2132</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>17.241379</td>\n",
       "      <td>16.091954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>7.298851</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Torralba, Antonio</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fei-Fei, Li</td>\n",
       "      <td>59</td>\n",
       "      <td>615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>3.458333</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Roy, Kaushik</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chen, C. L.Philip</td>\n",
       "      <td>95</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4</td>\n",
       "      <td>31.583333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chang, Shih Fu</td>\n",
       "      <td>59</td>\n",
       "      <td>1176</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26</td>\n",
       "      <td>8.155556</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Torr, Philip H.S.</td>\n",
       "      <td>62</td>\n",
       "      <td>2302</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.450980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18</td>\n",
       "      <td>5.568627</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Liu, Huan</td>\n",
       "      <td>8</td>\n",
       "      <td>844</td>\n",
       "      <td>113.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.625000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Song, Dawn</td>\n",
       "      <td>62</td>\n",
       "      <td>3793</td>\n",
       "      <td>14.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.705882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34</td>\n",
       "      <td>5.509804</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Kumar, Neeraj</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zhang, Hongjiang</td>\n",
       "      <td>60</td>\n",
       "      <td>351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.769231</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5.480769</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Papadimitriou, Christos</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wu, Ke</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rappaport, Theodore</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gao, Wen</td>\n",
       "      <td>99</td>\n",
       "      <td>2064</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>7.526882</td>\n",
       "      <td>5.376344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58</td>\n",
       "      <td>6.053763</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Zhang, Huaguang</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Liu, Xiaohui</td>\n",
       "      <td>76</td>\n",
       "      <td>4801</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55</td>\n",
       "      <td>3.261538</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Liu, Bing</td>\n",
       "      <td>53</td>\n",
       "      <td>6065</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>20.454545</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30</td>\n",
       "      <td>9.863636</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  Publications  Total citations  Median citations  \\\n",
       "0        Herrera, Francisco             9               59               3.0   \n",
       "1              Tao, Dacheng             2                3               1.5   \n",
       "2             Yu, Philip S.             3                7               1.0   \n",
       "3        Jordan, Michael I.            95             3531               3.0   \n",
       "4          Huang, Thomas S.            21              347               5.0   \n",
       "5            Wang, Xiaogang            97             2985              17.0   \n",
       "6                Zhang, Rui            99             5733               8.0   \n",
       "7                Zhang, Lei            87             2562              13.0   \n",
       "8               Li, Xuelong             5               35               3.0   \n",
       "9              Zhang, David            79             3279              22.0   \n",
       "10      Schölkopf, Bernhard             2               21              10.5   \n",
       "11            Zhou, Zhi Hua            91             2685              15.0   \n",
       "12          Davis, Larry S.             8               11               1.0   \n",
       "13          Pedrycz, Witold             6               71              10.5   \n",
       "14                Sun, Jian            99             2132               8.0   \n",
       "15        Torralba, Antonio             3                3               0.0   \n",
       "16              Fei-Fei, Li            59              615               3.0   \n",
       "17             Roy, Kaushik             8               64               8.0   \n",
       "18        Chen, C. L.Philip            95              223               0.0   \n",
       "19           Chang, Shih Fu            59             1176               5.0   \n",
       "20        Torr, Philip H.S.            62             2302               4.5   \n",
       "21                Liu, Huan             8              844             113.0   \n",
       "22               Song, Dawn            62             3793              14.5   \n",
       "23            Kumar, Neeraj             4                9               2.5   \n",
       "24         Zhang, Hongjiang            60              351               3.0   \n",
       "25  Papadimitriou, Christos             6                8               1.0   \n",
       "26                   Wu, Ke             9               99              11.0   \n",
       "27      Rappaport, Theodore             4               19               0.0   \n",
       "28                 Gao, Wen            99             2064              11.0   \n",
       "29          Zhang, Huaguang            17               33               0.0   \n",
       "30             Liu, Xiaohui            76             4801              36.0   \n",
       "31                Liu, Bing            53             6065              17.0   \n",
       "\n",
       "    h-index  h-frac-index  hm-index  h-leadership-index  % first author  \\\n",
       "0         4             1         0                   4       16.666667   \n",
       "1         1             0         0                   1        0.000000   \n",
       "2         1             1         0                   1      100.000000   \n",
       "3        23            15        19                  23        6.578947   \n",
       "4         9             5         5                   8       16.666667   \n",
       "5        31             4        32                  30       52.127660   \n",
       "6        30             0         7                  26        0.000000   \n",
       "7        27             9        16                  26       15.789474   \n",
       "8         3             1         0                   2       25.000000   \n",
       "9        32            12        24                  30       28.571429   \n",
       "10        2             2         0                   2        0.000000   \n",
       "11       31            12        15                  30       24.705882   \n",
       "12        2             1         2                   1       40.000000   \n",
       "13        5             3         0                   5       60.000000   \n",
       "14       25             6        14                  24       17.241379   \n",
       "15        1             1         0                   1      100.000000   \n",
       "16       14             6        17                  14       25.000000   \n",
       "17        5             2         0                   5       12.500000   \n",
       "18        5             0         3                   5        0.000000   \n",
       "19       17             8         5                  17        0.000000   \n",
       "20       13             6        10                  13        0.000000   \n",
       "21        8             6         0                   8       25.000000   \n",
       "22       25            12        11                  25        0.000000   \n",
       "23        2             0         0                   2        0.000000   \n",
       "24       11             3        10                  10        5.769231   \n",
       "25        2             0         1                   1       25.000000   \n",
       "26        7             3         2                   6       88.888889   \n",
       "27        1             1         0                   1        0.000000   \n",
       "28       23             9        17                  21        7.526882   \n",
       "29        3             1         1                   2        0.000000   \n",
       "30       37            19        20                  36       30.769231   \n",
       "31       22             8         6                  22       20.454545   \n",
       "\n",
       "    % last author  % single author  Median author position  i10-index  \\\n",
       "0        0.000000         0.000000                     2.5          2   \n",
       "1      100.000000         0.000000                     8.0          0   \n",
       "2        0.000000         0.000000                     1.0          0   \n",
       "3       65.789474         1.315789                     3.0         35   \n",
       "4       50.000000         5.555556                     2.0          8   \n",
       "5        5.319149         0.000000                     1.0         68   \n",
       "6       36.708861         0.000000                     9.0         46   \n",
       "7       17.105263         0.000000                     3.0         52   \n",
       "8        0.000000         0.000000                     3.0          1   \n",
       "9       36.363636         9.090909                     2.0         55   \n",
       "10     100.000000         0.000000                     4.0          1   \n",
       "11      16.470588         0.000000                     3.0         56   \n",
       "12      60.000000        20.000000                     2.0          0   \n",
       "13      80.000000        40.000000                     1.0          4   \n",
       "14      16.091954         0.000000                     3.0         45   \n",
       "15     100.000000       100.000000                     1.0          0   \n",
       "16      37.500000        20.833333                     2.0         16   \n",
       "17       0.000000         0.000000                     4.5          2   \n",
       "18      37.500000         0.000000                     4.5          4   \n",
       "19      62.222222         0.000000                     5.0         26   \n",
       "20      27.450980         0.000000                     4.0         18   \n",
       "21       0.000000         0.000000                     2.0          8   \n",
       "22      64.705882         0.000000                     5.0         34   \n",
       "23      33.333333         0.000000                     4.0          0   \n",
       "24      19.230769         0.000000                     2.0         12   \n",
       "25       0.000000         0.000000                     2.0          0   \n",
       "26      11.111111         0.000000                     1.0          5   \n",
       "27     100.000000         0.000000                     2.0          1   \n",
       "28       5.376344         0.000000                     4.0         58   \n",
       "29      50.000000         0.000000                     2.5          1   \n",
       "30      20.000000         0.000000                     2.0         55   \n",
       "31       9.090909         0.000000                     3.0         30   \n",
       "\n",
       "    Average number of Authors  Median number of Authors  \n",
       "0                   11.666667                      11.5  \n",
       "1                    8.000000                       8.0  \n",
       "2                    4.500000                       4.5  \n",
       "3                    3.934211                       4.0  \n",
       "4                    3.277778                       3.0  \n",
       "5                    3.787234                       3.0  \n",
       "6                  544.164557                      10.0  \n",
       "7                    5.184211                       5.0  \n",
       "8                    7.750000                       8.0  \n",
       "9                    4.714286                       4.0  \n",
       "10                   4.000000                       4.0  \n",
       "11                   6.647059                       6.0  \n",
       "12                   2.800000                       2.0  \n",
       "13                   2.000000                       2.0  \n",
       "14                   7.298851                       7.0  \n",
       "15                   1.000000                       1.0  \n",
       "16                   3.458333                       3.5  \n",
       "17                   8.125000                       8.5  \n",
       "18                  31.583333                       6.0  \n",
       "19                   8.155556                       6.0  \n",
       "20                   5.568627                       5.0  \n",
       "21                   9.625000                      10.0  \n",
       "22                   5.509804                       5.0  \n",
       "23                   6.333333                       7.0  \n",
       "24                   5.480769                       6.0  \n",
       "25                   7.250000                       3.5  \n",
       "26                   2.555556                       2.0  \n",
       "27                   2.000000                       2.0  \n",
       "28                   6.053763                       6.0  \n",
       "29                   3.833333                       4.0  \n",
       "30                   3.261538                       3.0  \n",
       "31                   9.863636                       7.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from calculate import *\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "filename = 'top_CS_researcher_by_h_index.json'\n",
    "\n",
    "def read_data(filepath=filename):\n",
    "    try:\n",
    "        with open(filepath, 'r') as fp:\n",
    "            return json.load(fp)\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "rows = []\n",
    "authors = read_data()\n",
    "for author in authors:\n",
    "    if h_index(author['publications']) > 50:\n",
    "        # All top 300 authors have higher h-indices so\n",
    "        # incorrect author got mined\n",
    "        continue\n",
    "    try:\n",
    "        rows.append({\n",
    "            'Name': author['name'],\n",
    "            'Publications': len(author['publications']),\n",
    "            'Total citations': total_citations(author['publications']),\n",
    "            'Median citations': median_citations(author['publications']),\n",
    "            'h-index': h_index(author['publications']),\n",
    "            'h-frac-index': h_frac_index(author['publications']),\n",
    "            'hm-index': hm_index(author['publications']),\n",
    "            'h-leadership-index': h_leadership_index(author['scopus_id'], author['publications']),\n",
    "            '% first author': percent_first_author(author['scopus_id'], author['publications']),\n",
    "            '% last author': percent_last_author(author['scopus_id'], author['publications']),\n",
    "            '% single author': percent_single_author(author['publications']),\n",
    "            'Median author position': median_author_position(author['scopus_id'], author['publications']),\n",
    "            # 'cscore':\n",
    "            'i10-index': i10_index(author['publications']),\n",
    "            'Average number of Authors': mean_coauthors(author['publications']),\n",
    "            'Median number of Authors': median_coauthors(author['publications']),\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing author: {author['name']}\")\n",
    "\n",
    "authors_df = pd.DataFrame(rows)\n",
    "display(authors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update (bug observed)\n",
    "* I have observed that for some authors, when mining their co-authors, Scopus API returns an empty list.\n",
    "* This results in an overall incorrect calculation of the h-leadership index\n",
    "* I am yet to trace down the root cause behind this and would work on this post my midsemester break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
