{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and storing data utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = 'results/top_CS_researcher_by_h_index.json'\n",
    "\n",
    "def read_data(filepath=filename):\n",
    "    try:\n",
    "        with open(filepath, 'r') as fp:\n",
    "            return json.load(fp)\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "def store_data(data, filepath=filename):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        fp.write(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Publications for an author\n",
    "\n",
    "* We find the top authors in Computer Science - based on `h-index`\n",
    "* We find the `top 100 pubs` for every author and then\n",
    "* We calculate\n",
    "    - h-index\n",
    "    - c-score (log(total_citations) + log(h) + log(hm) + log(%first_author) + log(%first_last) + log(%first_last_single)\n",
    "    - h-leadership-index (inverted bell curve)\n",
    "\n",
    "* Things to remember:\n",
    "    - we are not ranking individuals but creating an index\n",
    "* Other notes\n",
    "    - cscore does not include Field-wise citation index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import pandas as pd\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "# Read the Stanford 2% ranking excel file\n",
    "df = pd.read_excel('Table_1_Authors_career_2022_pubs_since_1788_wopp_extracted_202310.xlsx', sheet_name='Data', engine='openpyxl')\n",
    "# We are only considering the Computer Science subject for this study\n",
    "df = df.loc[df['sm-field'] == 'Information & Communication Technologies']\n",
    "# NOTE: The cutoff year is 2022,and h column name changes based on cutoff year\n",
    "df = df.sort_values(by='h22', ascending=False)\n",
    "\n",
    "# A mapping between Stanford's top 2% ranking `sm-field` and Scopus API `SUBJECTAREA`\n",
    "subject_areas_mapping = {\n",
    "    'Information & Communication Technologies': ['COMP', 'MULT']\n",
    "}\n",
    "\n",
    "# Set up your Scopus API key\n",
    "api_key = '5aa908d24ec7e71ef0cf68cb3bff134d'\n",
    "\n",
    "# Define the Scopus API endpoint for author search\n",
    "scopus_search_url = 'https://api.elsevier.com/content/search/author'\n",
    "\n",
    "# Define the Scopus API endpoint for retrieving author's publications\n",
    "scopus_search_publications_url = 'https://api.elsevier.com/content/search/scopus'\n",
    "\n",
    "# Define the Scopus Abstract Retrieval API to get detailed information about the publication\n",
    "scopus_abstract_url = f'https://api.elsevier.com/content/abstract/eid'\n",
    "\n",
    "# Set up headers with your API key\n",
    "headers = {\n",
    "    'X-ELS-APIKey': api_key,\n",
    "}\n",
    "\n",
    "\n",
    "# Utility methods\n",
    "def get_author_names(author_full_name):\n",
    "    # Split the full name into first and last names\n",
    "    names = author_full_name.split(', ', 1)\n",
    "    first_name = names[-1]\n",
    "    last_name = names[0] if len(names)==2 else ''\n",
    "    return first_name, last_name\n",
    "\n",
    "def get_country_name(country_code):\n",
    "    try:\n",
    "        country_name = pycountry.countries.get(alpha_3=country_code).name\n",
    "        return country_name\n",
    "    except AttributeError:\n",
    "        # Handle cases where the country code is not found\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def sort_author(author, country, affiliation):\n",
    "    cites = int(author.get('document-count', 0))\n",
    "    country_name = author.get('affiliation-current', {}).get('affiliation-country', '')\n",
    "    affiliation_name = author.get('affiliation-current', {}).get('affiliation-name', '')\n",
    "    return cites, country_name == country, affiliation_name == affiliation\n",
    "\n",
    "\n",
    "# Function to search for an author in Scopus using name, affiliation, country, and field\n",
    "def search_author(author_name, affiliation, country_code, field, exclude=list()):\n",
    "    first_name, last_name = get_author_names(author_name)\n",
    "    subject_areas = subject_areas_mapping.get(field, [])\n",
    "    country_name = get_country_name(country_code)\n",
    "\n",
    "    query = f'AUTHLASTNAME({last_name}) AND AUTHFIRST({first_name}) AND {\" OR \".join(map(lambda s: f\"SUBJAREA({s})\", subject_areas))}'\n",
    "    response = requests.get(scopus_search_url, params={'query': query, 'count': 200}, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get('search-results', {}).get('entry', [])\n",
    "        # exclude authors already in the list\n",
    "        results = [r for r in results if r.get('dc:identifier') not in exclude]\n",
    "        # sort the authors based on the number of documents, affiliation country, and affiliation name\n",
    "        sort_key = partial(sort_author, country=country_name, affiliation=affiliation)\n",
    "        results.sort(key=sort_key, reverse=True)\n",
    "\n",
    "        return results[0] if results else None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch all publications for an author using Scopus Author ID\n",
    "def fetch_author_publications(author_id, publications=None, start_index=0, top=100):\n",
    "    if not publications:\n",
    "        publications = []\n",
    "\n",
    "    query = f'AU-ID({author_id})'\n",
    "    response = requests.get(scopus_search_publications_url, params={\n",
    "        'query': query,\n",
    "        'start': start_index,\n",
    "        'count': 200, # Maximum can be 200\n",
    "        # 'sort': '-citedby-count' # Scopus API sort does not work\n",
    "    }, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        search_results = response.json().get('search-results', {}).get('entry', [])\n",
    "\n",
    "        for entry in search_results:\n",
    "            publication_data = {\n",
    "                'title': entry.get('dc:title', ''),\n",
    "                'eid': entry.get('eid', ''),\n",
    "                'citations': int(entry.get('citedby-count', 0)),\n",
    "                'publication_name': entry.get('prism:publicationName', ''),\n",
    "                'issn': entry.get('prism:issn', ''),\n",
    "                'cover_date': entry.get('prism:coverDate', ''),\n",
    "                'venue': entry.get('prism:aggregationType', ''),\n",
    "                'volume': entry.get('prism:volume', ''),\n",
    "                'issue': entry.get('prism:issueIdentifier', ''),\n",
    "                'page_range': entry.get('prism:pageRange', ''),\n",
    "                'doi': entry.get('prism:doi', ''),\n",
    "            }\n",
    "            publications.append(publication_data)\n",
    "\n",
    "        # Fetch the next set of publications if available and limit is not reached\n",
    "        start_index += len(search_results)\n",
    "        if start_index < int(response.json().get('search-results', {}).get('opensearch:totalResults', 0)):\n",
    "            return fetch_author_publications(author_id, publications, start_index, top)\n",
    "        else:\n",
    "            # We return the top publications based on citations\n",
    "            publications.sort(key=lambda p: p['citations'], reverse=True)\n",
    "            publications = publications[:100]\n",
    "            for publication in publications:\n",
    "                authors = []\n",
    "                abstract_url = f'{scopus_abstract_url}/{entry.get(\"eid\", \"\")}'\n",
    "                response_abstract = requests.get(abstract_url, headers=headers)\n",
    "                if response_abstract.status_code == 200:\n",
    "                    author_data = xmltodict.parse(response_abstract.text).get('abstracts-retrieval-response', {}).get('authors', []).get('author', [])\n",
    "                    if not isinstance(author_data, list): # If only one author\n",
    "                        author_data = [author_data]\n",
    "                    authors = list(map(lambda a: {\n",
    "                            'scopus_id': a['@auid'],\n",
    "                            'name': a.get('ce:indexed-name', ''),\n",
    "                        }, author_data))\n",
    "                publication['authors'] = authors\n",
    "\n",
    "    return publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jain, Anil: Skipped\n",
      "Bengio, Yoshua: Skipped\n",
      "Poor, H. Vincent: Skipped\n",
      "Herrera, Francisco: Skipped\n",
      "Han, Jiawei\n",
      "Tao, Dacheng\n",
      "Gool, Luc Van\n",
      "Zisserman, Andrew\n",
      "Cao, Jinde\n",
      "Yu, Philip S.\n",
      "Jordan, Michael I.\n",
      "Xu, Zeshui\n",
      "Huang, Thomas S.\n",
      "Malik, Jitendra\n",
      "Wang, Xiaogang\n",
      "Giannakis, Georgios B.\n",
      "Buyya, Rajkumar\n",
      "van der Aalst, Wil M.P.\n",
      "Vasilakos, Athanasios V.\n",
      "Zhang, Rui\n",
      "Shen, Xuemin\n",
      "Yang, Ming Hsuan\n",
      "Zhang, Lei\n",
      "Yan, Shuicheng\n",
      "Li, Xuelong\n",
      "Zhang, David\n",
      "Schölkopf, Bernhard\n",
      "Akyildiz, Ian F.\n",
      "Heath, Robert W.\n",
      "Acharya, U. Rajendra\n",
      "Müller, Klaus Robert\n",
      "Tang, Xiaoou\n",
      "Schmid, Cordelia\n",
      "Vaidyanathan, Sundarapandian\n",
      "Shenker, Scott\n",
      "Cui, Tie Jun\n",
      "Shen, Dinggang\n",
      "Kanade, T.\n",
      "Hinton, Geoffrey\n",
      "Tong, Shaocheng\n",
      "Koller, Daphne\n",
      "Han, Zhu\n",
      "Stoica, Ion\n",
      "Darrell, Trevor\n",
      "Manning, Christopher D.\n",
      "Zhou, Mengchu\n",
      "Leskovec, Jure\n",
      "Faloutsos, Christos\n",
      "Ng, Andrew Y.\n",
      "Chellappa, Rama\n",
      "Herrera-Viedma, Enrique\n",
      "Schiele, Bernt\n",
      "Yager, Ronald R.\n",
      "Baldi, Pierre\n",
      "Pentland, Alex Sandy\n",
      "Poggio, Tomaso\n",
      "Zhou, Zhi Hua\n",
      "Niyato, Dusit\n",
      "Guibas, Leonidas\n",
      "Davis, Larry S.\n",
      "Freeman, William T.\n",
      "Yao, Xin\n",
      "Yang, Qiang\n",
      "Pedrycz, Witold\n",
      "Bovik, Alan C.\n",
      "Sun, Jian\n",
      "Foster, Ian T.\n",
      "Shah, Mubarak\n",
      "Torralba, Antonio\n",
      "Suganthan, P. N.\n",
      "Towsley, Don\n",
      "Hanzo, Lajos\n",
      "Leung, Victor C.M.\n",
      "Black, Michael J.\n",
      "Tan, Tieniu\n",
      "Boneh, Dan\n",
      "Garcia-Molina, Hector\n",
      "Alouini, Mohamed Slim\n",
      "Fei-Fei, Li\n",
      "Li, Geoffrey Ye\n",
      "Smola, Alex\n",
      "Stoica, Petre\n",
      "Li, Y.\n",
      "Wang, Jun\n",
      "Unser, Michael\n",
      "Szeliski, Rick\n",
      "Molisch, Andreas F.\n",
      "Roy, Kaushik\n",
      "Dubois, Didier\n",
      "Chen, C. L.Philip\n",
      "Debbah, Mérouane\n",
      "Estrin, Deborah\n",
      "Balakrishnan, Hari\n",
      "Chang, Shih Fu\n",
      "Ding, Zhiguo\n",
      "Yang, Yang\n",
      "Benini, Luca\n",
      "Andrews, Jeffrey G.\n",
      "Gerla, Mario\n",
      "Torr, Philip H.S.\n",
      "Yuille, Alan L.\n",
      "Nayar, Shree\n",
      "Liu, Huan\n",
      "Song, Dawn\n",
      "Culler, David\n",
      "Kleinberg, Jon\n",
      "Sapiro, Guillermo\n",
      "Van Der Vleuten, Cees\n",
      "Kumar, Neeraj\n",
      "Zhang, Hongjiang\n",
      "Papadimitriou, Christos\n",
      "LeCun, Yann\n",
      "Wu, Ke\n",
      "Choo, Kim Kwang Raymond\n",
      "Seidel, Hans Peter\n",
      "Hossain, Ekram\n",
      "Chen, Shyi Ming\n",
      "Srivastava, Mani\n",
      "Rappaport, Theodore\n",
      "Gao, Wen\n",
      "Nie, Feiping\n",
      "Jennings, Nicholas R.\n",
      "Baraniuk, Richard\n",
      "Liang, Ying Chang\n",
      "Cichocki, Andrzej\n",
      "Schober, Robert\n",
      "Schuller, Björn W.\n",
      "Pollefeys, Marc\n",
      "Cohen-Or, Daniel\n",
      "Li, Stan Z.\n",
      "Shen, Chunhua\n",
      "Ayache, Nicholas\n",
      "Zhang, Yan\n",
      "Donoho, David\n",
      "Huang, Tingwen\n",
      "Perona, Pietro\n",
      "Hebert, Martial\n",
      "Lyu, Michael R.\n",
      "Mutlu, Onur\n",
      "Fridrich, Jessica\n",
      "Chua, Tat Seng\n",
      "Zhang, Huaguang\n",
      "Theis, Fabian\n",
      "Deb, Kalyanmoy\n",
      "Guizani, Mohsen\n",
      "Shneiderman, Ben\n",
      "Shao, Ling\n",
      "Yu, Fei Richard\n",
      "Cambria, Erik\n",
      "Dwivedi, Yogesh K.\n",
      "Haas, Harald\n",
      "Fua, Pascal\n",
      "Henzinger, Thomas A.\n",
      "Eldar, Yonina C.\n",
      "Liu, Xiaohui\n",
      "Shin, Kang G.\n",
      "Li, Jian\n",
      "Prade, Henri\n",
      "Cohn, Jeffrey F.\n",
      "Liu, K. J.Ray\n",
      "Cremers, Daniel\n",
      "Rexford, Jennifer\n",
      "Liu, Bing\n",
      "Metaxas, Dimitris N.\n",
      "Slater, Mel\n",
      "Wu, Jie\n",
      "Win, Moe Z.\n",
      "Chen, Xiaohong\n",
      "Rebeiz, Gabriel\n",
      "Vetterli, Martin\n",
      "Goldsmith, Andrea\n",
      "Liu, Derong\n",
      "Levine, Sergey\n",
      "Wei, Guiwu\n",
      "Jia, Jiaya\n",
      "Stankovic, John\n",
      "Rodrigues, Joel J.P.C.\n",
      "Shum, Heung Yeung\n",
      "Li, Hongyi\n",
      "Bellare, Mihir\n",
      "Tzeng, Gwo Hshiung\n",
      "Jiao, Licheng\n",
      "Le, Quoc V.\n",
      "Chen, Min\n",
      "Ye, Jieping\n",
      "Pantic, Maja\n",
      "Abraham, Ajith\n",
      "Mukherjee, Biswanath\n",
      "Croft, W. Bruce\n",
      "Das, Sajal K.\n",
      "Bischof, Horst\n",
      "Picard, Rosalind W.\n",
      "Wang, Fei Yue\n",
      "Ney, Hermann\n",
      "Horowitz, Mark\n",
      "Yang, Xin She\n",
      "Castillo, Oscar\n",
      "Durand, Fredo\n",
      "Madden, Sam\n",
      "Urtasun, Raquel\n",
      "Feng, Jiashi\n",
      "Jin, Yaochu\n",
      "Elad, Michael\n",
      "Paulraj, Arogyaswami\n",
      "Bertino, Elisa\n",
      "Belongie, Serge\n",
      "Ghahramani, Zoubin\n",
      "Gandomi, Amir H.\n",
      "Efros, Alexei A.\n",
      "Bach, Francis\n",
      "Salakhutdinov, Ruslan\n",
      "Gross, M.\n",
      "Letaief, Khaled Ben\n",
      "Itoh, Tatsuo\n",
      "Zuo, Wangmeng\n",
      "Liao, Xiao Feng\n",
      "Ma, Wei Ying\n",
      "McCallum, Andrew\n",
      "Xing, Eric\n",
      "Weston, Jason\n",
      "Chen, Bin\n",
      "Keogh, Eamonn J.\n",
      "Gong, Shaogang\n",
      "Perrig, Adrian\n",
      "Liu, Wei\n",
      "Wang, Xiaodong\n",
      "Pietikäinen, Matti\n",
      "Mendel, Jerry M.\n",
      "Xu, Lida\n",
      "Alon, Noga\n",
      "Lu, Huchuan\n",
      "Low, Steven H.\n",
      "Kruegel, Christopher\n",
      "Govindan, Ramesh\n",
      "Mirjalili, Seyedali\n",
      "Katz, Randy\n",
      "Coello Coello, Carlos A.\n",
      "Giles, Lee\n",
      "Harman, Mark\n",
      "Theobalt, Christian\n",
      "Tarjan, Robert E.\n",
      "Aggarwal, Charu C.\n",
      "Sangiovanni-Vincentelli, Alberto L.\n",
      "Trivedi, Kishor\n",
      "Liu, Yunhao\n",
      "Saad, Walid\n",
      "Benbasat, Izak\n",
      "Heng, Pheng Ann\n",
      "Karger, David\n",
      "Chew, Weng Cho\n",
      "Chen, Hsinchun\n",
      "Hong, Wei\n",
      "Wang, Meng\n",
      "Kohli, Pushmeet\n",
      "Deng, Yong\n",
      "Zhang, Yu Dong\n",
      "Zheng, Yu\n",
      "Navab, Nassir\n",
      "Vahdat, Amin\n",
      "Yao, Yiyu\n",
      "Abdelzaher, Tarek\n",
      "Schmidhuber, Jürgen\n",
      "Larsson, Erik G.\n",
      "Kahraman, Cengiz\n",
      "Matas, Jiří\n",
      "Ren, Kui\n",
      "Hanrahan, Pat\n",
      "Amari, Shun Ichi\n",
      "Luo, Jiebo\n",
      "He, Haibo\n",
      "Yang, Laurence T.\n",
      "Sayed, Ali H.\n",
      "Wong, Kin Lu\n",
      "Brox, Thomas\n",
      "Zhao, Lili\n",
      "Venkatesh, Viswanath\n",
      "Kittler, Josef\n",
      "Manocha, Dinesh\n",
      "Troster, Gerhard\n",
      "Horvitz, Eric\n",
      "Karagiannidis, George K.\n",
      "Rahmat-Samii, Yahya\n",
      "Naor, Moni\n",
      "Willsky, Alan\n",
      "Vardi, Moshe Y.\n",
      "Pei, Jian\n",
      "Cranor, Lorrie\n",
      "Ramchandran, Kannan\n",
      "Lou, Wenjing\n",
      "Ottersten, Bjorn\n",
      "Lin, Weisi\n",
      "Zhai, Cheng Xiang\n",
      "De Micheli, Giovanni\n",
      "Li, Shutao\n",
      "McKeown, Nick\n",
      "Dongarra, Jack\n",
      "Zeadally, Sherali\n",
      "Blei, David M.\n",
      "Sebe, Nicu\n",
      "Wang, Ling\n"
     ]
    }
   ],
   "source": [
    "# main code\n",
    "scopus_results=read_data()\n",
    "def fetch_authors(stop_at=100):\n",
    "    # Iterate through the rows of the DataFrame\n",
    "    for index, (row_index, row) in enumerate(df.iterrows()):\n",
    "        if index < len(scopus_results):\n",
    "            # Since data was previously obtained for these authors, we can skip them\n",
    "            print(f'{row[\"authfull\"]}: Skipped')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            author_name = row['authfull']\n",
    "            author_cscore = row['c']\n",
    "            affiliation = row['inst_name']\n",
    "            country_code = row['cntry']\n",
    "            field = row['sm-field']\n",
    "            print(author_name)\n",
    "\n",
    "            # Search for the author in Scopus\n",
    "            author_search_result = search_author(\n",
    "                author_name,\n",
    "                affiliation,\n",
    "                country_code,\n",
    "                field,\n",
    "                map(lambda x: x['scopus_id'], scopus_results)\n",
    "            )\n",
    "\n",
    "            # Process the search result as needed\n",
    "            if author_search_result is not None:\n",
    "                author_id = author_search_result.get('dc:identifier', '').split(':')[-1]\n",
    "                author_publications = fetch_author_publications(author_id)\n",
    "                scopus_results.append({\n",
    "                    'scopus_id': author_id,\n",
    "                    'name': author_name,\n",
    "                    'cscore': author_cscore,\n",
    "                    'publications': author_publications\n",
    "                })\n",
    "                if index >= stop_at-1:\n",
    "                    break\n",
    "            else:\n",
    "                raise Exception(f\"Author not found for: {author_name}, Affiliation: {affiliation}, Country: {country_code}, Field: {field}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    store_data(scopus_results)\n",
    "    # return scopus_results\n",
    "\n",
    "fetch_authors(stop_at=300)\n",
    "# TODO: Find correlation between hl-index, h-index and c-score\n",
    "# Find the remaining usage-limit for Scopus API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scopus_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics for the Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hardik/Documents/metrics/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/hardik/Documents/metrics/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Publications</th>\n",
       "      <th>Total citations</th>\n",
       "      <th>Median citations</th>\n",
       "      <th>h-index</th>\n",
       "      <th>h-frac-index</th>\n",
       "      <th>hm-index</th>\n",
       "      <th>h-leadership-index</th>\n",
       "      <th>% first author</th>\n",
       "      <th>% last author</th>\n",
       "      <th>% single author</th>\n",
       "      <th>Median author position</th>\n",
       "      <th>cscore</th>\n",
       "      <th>i10-index</th>\n",
       "      <th>Average number of Authors</th>\n",
       "      <th>Median number of Authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jain, Anil</td>\n",
       "      <td>100</td>\n",
       "      <td>80152</td>\n",
       "      <td>407.0</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.156287</td>\n",
       "      <td>100</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bengio, Yoshua</td>\n",
       "      <td>100</td>\n",
       "      <td>293961</td>\n",
       "      <td>672.0</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>18.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.146155</td>\n",
       "      <td>100</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poor, H. Vincent</td>\n",
       "      <td>100</td>\n",
       "      <td>48226</td>\n",
       "      <td>318.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.642852</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herrera, Francisco</td>\n",
       "      <td>100</td>\n",
       "      <td>63330</td>\n",
       "      <td>414.5</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.747378</td>\n",
       "      <td>100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Han, Jiawei</td>\n",
       "      <td>100</td>\n",
       "      <td>58691</td>\n",
       "      <td>317.0</td>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.673319</td>\n",
       "      <td>100</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Dongarra, Jack</td>\n",
       "      <td>100</td>\n",
       "      <td>16888</td>\n",
       "      <td>98.5</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.124214</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Zeadally, Sherali</td>\n",
       "      <td>100</td>\n",
       "      <td>17913</td>\n",
       "      <td>134.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.751489</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Blei, David M.</td>\n",
       "      <td>100</td>\n",
       "      <td>63183</td>\n",
       "      <td>115.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.676150</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Sebe, Nicu</td>\n",
       "      <td>100</td>\n",
       "      <td>17035</td>\n",
       "      <td>116.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.820937</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Wang, Ling</td>\n",
       "      <td>100</td>\n",
       "      <td>8535</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.012404</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  Publications  Total citations  Median citations  \\\n",
       "0            Jain, Anil           100            80152             407.0   \n",
       "1        Bengio, Yoshua           100           293961             672.0   \n",
       "2      Poor, H. Vincent           100            48226             318.0   \n",
       "3    Herrera, Francisco           100            63330             414.5   \n",
       "4           Han, Jiawei           100            58691             317.0   \n",
       "..                  ...           ...              ...               ...   \n",
       "275      Dongarra, Jack           100            16888              98.5   \n",
       "276   Zeadally, Sherali           100            17913             134.0   \n",
       "277      Blei, David M.           100            63183             115.0   \n",
       "278          Sebe, Nicu           100            17035             116.0   \n",
       "279          Wang, Ling           100             8535              54.0   \n",
       "\n",
       "     h-index  h-frac-index  hm-index  h-leadership-index  % first author  \\\n",
       "0        100            47         0                 100            30.0   \n",
       "1        100            39         0                 100            18.0   \n",
       "2        100           100         0                 100           100.0   \n",
       "3        100            84         0                 100             0.0   \n",
       "4        100            95         0                 100           100.0   \n",
       "..       ...           ...       ...                 ...             ...   \n",
       "275       72             0         0                   0             0.0   \n",
       "276       81             0         0                   0             0.0   \n",
       "277       75             0         0                   0             0.0   \n",
       "278       79             0         0                   0             0.0   \n",
       "279       51             0         0                   0             0.0   \n",
       "\n",
       "     % last author  % single author  Median author position    cscore  \\\n",
       "0             55.0              2.0                     2.0  5.156287   \n",
       "1             62.0              4.0                     3.0  5.146155   \n",
       "2            100.0            100.0                     1.0  4.642852   \n",
       "3              0.0              0.0                     2.0  4.747378   \n",
       "4              0.0              0.0                     1.0  4.673319   \n",
       "..             ...              ...                     ...       ...   \n",
       "275            0.0              0.0                     NaN  4.124214   \n",
       "276            0.0              0.0                     NaN  3.751489   \n",
       "277            0.0              0.0                     NaN  4.676150   \n",
       "278            0.0              0.0                     NaN  3.820937   \n",
       "279            0.0              0.0                     NaN  4.012404   \n",
       "\n",
       "     i10-index  Average number of Authors  Median number of Authors  \n",
       "0          100                       3.24                       3.0  \n",
       "1          100                       5.44                       4.0  \n",
       "2          100                       1.00                       1.0  \n",
       "3          100                       3.00                       3.0  \n",
       "4          100                       2.00                       2.0  \n",
       "..         ...                        ...                       ...  \n",
       "275        100                        NaN                       NaN  \n",
       "276        100                        NaN                       NaN  \n",
       "277        100                        NaN                       NaN  \n",
       "278        100                        NaN                       NaN  \n",
       "279        100                        NaN                       NaN  \n",
       "\n",
       "[280 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from calculate import *\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "\n",
    "def read_data(filepath=filename):\n",
    "    try:\n",
    "        with open(filepath, 'r') as fp:\n",
    "            return json.load(fp)\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "rows = []\n",
    "authors = read_data()\n",
    "for author in authors:\n",
    "    if h_index(author['publications']) < 50:\n",
    "        # All top 300 authors have higher h-indices so\n",
    "        # incorrect author got mined\n",
    "        continue\n",
    "    try:\n",
    "        rows.append({\n",
    "            'Name': author['name'],\n",
    "            'Publications': len(author['publications']),\n",
    "            'Total citations': total_citations(author['publications']),\n",
    "            'Median citations': median_citations(author['publications']),\n",
    "            'h-index': h_index(author['publications']),\n",
    "            'h-frac-index': h_frac_index(author['publications']),\n",
    "            'hm-index': hm_index(author['publications']),\n",
    "            'h-leadership-index': h_leadership_index(author['scopus_id'], author['publications']),\n",
    "            '% first author': percent_first_author(author['scopus_id'], author['publications']),\n",
    "            '% last author': percent_last_author(author['scopus_id'], author['publications']),\n",
    "            '% single author': percent_single_author(author['publications']),\n",
    "            'Median author position': median_author_position(author['scopus_id'], author['publications']),\n",
    "            'cscore': author['cscore'],\n",
    "            'i10-index': i10_index(author['publications']),\n",
    "            'Average number of Authors': mean_coauthors(author['publications']),\n",
    "            'Median number of Authors': median_coauthors(author['publications']),\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing author: {author['name']}\")\n",
    "\n",
    "authors_df = pd.DataFrame(rows)\n",
    "authors_df.to_csv('results/metrics.csv', sep=',', index=False)\n",
    "display(authors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 99,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 99,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 97,\n",
       " 99,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_df['h-leadership-index'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let this job continue running!!\n",
    "Open a new window if need be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
